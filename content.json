{"posts":[{"title":"谷歌Colab使用心得","text":"最近做毕业论文，需要做深度学习的目标识别，但是苦于算力危机，这时候发现了Google提供的超级好用的Colab，使用上手很快，但是有一些需要注意的点，做了一点总结。 最近一直在折腾毕业论文，终于可以抽一点时间写点笔记，鉴于我的记性向来很差，这还是相当有必要的，免得以后再做的时候把现在走过的弯路全走一遍。之前做图像分类很多经验就没总结，到最后全重新踩坑了。废话少说，开始说正事。 谷歌的Colab基本上就是一个深度魔改的Jupyter Notebook，但是谷歌非常良心地提供了Python的运行时，因此我们就可以直接在云端运行任何.ipynb格式的笔记了，最为让人感动的是，谷歌还提供免费的GPU资源用，拯救了我毕业论文的算力危机。当然，要是有台正经的工作站就没这么麻烦了。 首先，Colab可以使用IPython的magic command，例如%matplotlib等，但是Colab里有一部分特有的magic command，例如指定tensorflow版本的命令%tensorflow_version 1.x ，由于tensorflow的object detection API还没有适配TF2.0版本，但是现在的Colab已经是默认使用TF2.0了，因此必须要在import之前就指定TF版本，否则指定完以后需要重启运行时。 同样的，很多时候我们还需要运行一些shell command，比如需要装一些缺失的包，git clone之类，可以用![shell command]，例如!pip3 install pycocotools即可。 接下来，不可避免地我们会遇到一些需要进行I/O操作的场景。直接在Colab提供的运行时中储存重要的数据是很不推荐的行为。试想训练了好久的模型，吃着火锅儿，唱着歌，突然就被谷歌把资源收回了，哭都没处哭。因此我采用的办法是用Google Drive的API，直接mount云端硬盘，这样各种操作都比较方便，而不需要次次去和云端硬盘的API打交道。使用也很简单，按照文档授权后填token即可，美中不足的就是每次mount都要填token，不过无伤大雅。需要注意的是，mount后云端硬盘的文件夹名会叫My Drive，中间的空格在各种路径中需要转义成My\\ Drive。 另外，如果要使用GPU，需要申请有GPU的运行时，在“修改-笔记本设置”里可以进行修改。需要注意GPU资源还是比较宝贵的，出于不被限额和遵守道德的原因，在编辑、调试笔记的时候不要用占用GPU运行时，等一切就绪再申请。同样即使是无GPU的运行时，也不要长久占用。 最后，也是最重要的——多看文档。刚开始没看文档，以为GPU资源不需要自己申请，结果拿CPU跑了训练，占用时间极长不说，还被暂时限制使用了，因此看文档真的很重要。 目前就这些比较重要的体会了，如果在之后有新的需要记录的内容，还会继续更新这篇博文。","link":"/Colab-Review/"},{"title":"解决EndNote X9 大客户版在Catalina下无法安装的问题","text":"由于论文中要搞很多参考文献，我需要用BibTeX生成引用和参考文献，这些东西我肯定不会想去手动管理，手写.bib既累又容易出错。因此想到用EndNote。但是在macOS 10.15 Catalina上安装EndNote的时候出了些问题。 本来我可以用同济的EndNote授权，只可惜学校图书馆网站不知道搞什么鬼，下载链接会404，没办法就网上找个别的学校的授权了。毕竟盗版也只是个法律概念，我本身是有正版的资格，只不过因为莫名其妙的原因拿不到罢了。 在网上下载了一个深圳大学的授权版本，发现打不开，提示这个： 起初怀疑是Catalina不支持32位程序的原因，但是实际上并不是这个问题。问题似乎出在macOS的保护机制，从网络上下载的这个安装APP有扩展属性，会阻止直接运行，平常会询问这个APP来自网络，是否要打开，但是这次直接不由分说地阻止了。因此要把扩展属性去掉，但是DMG是只读的，因此要把安装APP放进/Applications里。 1$ cp -r /Volumes/EndNote\\ X9\\ Installer/Install\\ EndNote\\ X9.app ~/Applications/ 之后去除扩展属性 1$ sudo xattr -rd com.apple.quarantine /Applications/Install\\ EndNote\\ X9.app 这样就可以直接在/Applications里打开安装了。 参考资料：https://www.macbl.com/article/tips/2123","link":"/endnote-catalina-fix/"},{"title":"LaTeX中文句号和句点的设置","text":"最近在搞毕业论文的$\\LaTeX$模版，当中遇到一点问题，就是文章的样式里中英文的句号都是一个句点，最后发现是cls文件里xeCJK宏包的设置问题。 1\\setCJKmainfont[Mapping = fullwidth-stop,BoldFont=STHeitiSC-Medium, ItalicFont=STKaitiSC-Regular]{STSongti-SC-Regular} 问题就出在那个Mapping上，fullwidth-stop会把所有句号替换成句点。当然Mapping的选项不止这几个，还可以把句点改成句号，繁简体中文转换等，这个问题的解决也得益于一位前辈的博文，非常感谢。 相关博文链接：https://matnoble.me/tech/latex/latex-period/","link":"/latex-cjk-punct/"},{"title":"在Docker中搭建PointCloudLibrary的开发环境","text":"最近需要做点云处理，PCL是个比较有用的包，但是只能C++，比起Python确实要麻烦一点。在自己的MacBook上折腾那些依赖之类确实比较危险，搞坏了又要花时间精力去弄，况且MacBook的性能确实经受不起点云数据的折腾。最后想到用docker来搞了。DockerHub上只有一个用PCL1.8.0搭建的镜像，有点老掉牙了，于是乎自己搞了一套出来。本来还想直接在镜像里配好VIM，但是Ubuntu 16.04的源里面Python和VIM的版本都太低了，都得源码编译，暂时先放弃了。用VSCode+Docker扩展已经很香了，不瞎折腾了。 Dockerfile在这:GitHub Dockerfile里build的时候指定了clash的代理用来加速一些PPA，同时APT改成了科大源。 或者直接Pull镜像也可以:docker pull erwinqi/pcl:v1.11.1","link":"/pointcloudlibrary-docker/"},{"title":"分割COCO Format的目标识别数据集","text":"最近需要利用coco format的数据集做目标识别的训练，个人比较熟悉tensorflow，但是tensorflow的Object Detection API接受的是tfrecord格式数据，为了分别生成train validation使用的tfrecord，我需要把coco format的数据集分割一下，在这里遇到了一些麻烦。 在网上找到了别人做好的轮子： https://github.com/ashnair1/COCO-Assistant 但是问题在于，这个操作数据集的工具居然只能merge，不能split，无奈找了GitHub上这位同学的代码，对其中一些内容做了修改，最终实现了需求。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163from pycocotools.coco import COCOfrom pycocotools import mask as cocomaskimport numpy as npimport skimage.io as ioimport matplotlib.pyplot as pltimport pylabimport randomimport osfrom pycococreatortools import pycococreatortools as ptimport jsonimport randomroot_dir = '/root'INFO = { &quot;description&quot;: &quot;Construction Site Image Dataset&quot;, &quot;url&quot;: &quot;&quot;, &quot;version&quot;: &quot;0.2.0&quot;, &quot;year&quot;: 2020, &quot;contributor&quot;: &quot;&quot;,}LICENSES = [ { &quot;id&quot;: 1, &quot;name&quot;: &quot;Attribution-NonCommercial-ShareAlike License&quot;, &quot;url&quot;: &quot;http://creativecommons.org/licenses/by-nc-sa/2.0/&quot; }]CATEGORIES = [ { &quot;id&quot;: 1, &quot;name&quot;: &quot;truck&quot;, &quot;supercategory&quot;: &quot;class&quot; }, { &quot;id&quot;: 2, &quot;name&quot;: &quot;excavator&quot;, &quot;supercategory&quot;: &quot;class&quot; }, { &quot;id&quot;: 3, &quot;name&quot;: &quot;crane&quot;, &quot;supercategory&quot;: &quot;class&quot; }, { &quot;id&quot;: 4, &quot;name&quot;: &quot;other_machine&quot;, &quot;supercategory&quot;: &quot;class&quot; }, { &quot;id&quot;: 5, &quot;name&quot;: &quot;precast_concrete&quot;, &quot;supercategory&quot;: &quot;class&quot; }, { &quot;id&quot;: 6, &quot;name&quot;: &quot;steel&quot;, &quot;supercategory&quot;: &quot;class&quot; }, { &quot;id&quot;: 7, &quot;name&quot;: &quot;aggregates&quot;, &quot;supercategory&quot;: &quot;class&quot; }, { &quot;id&quot;: 8, &quot;name&quot;: &quot;timber&quot;, &quot;supercategory&quot;: &quot;class&quot; }, { &quot;id&quot;: 9, &quot;name&quot;: &quot;other_materials&quot;, &quot;supercategory&quot;: &quot;class&quot; }, { &quot;id&quot;: 10, &quot;name&quot;: &quot;personnel&quot;, &quot;supercategory&quot;: &quot;class&quot; },]coco_output_train = { &quot;info&quot;: INFO, &quot;licenses&quot;: LICENSES, &quot;categories&quot;: CATEGORIES, &quot;images&quot;: [], &quot;annotations&quot;: []}coco_output_val = { &quot;info&quot;: INFO, &quot;licenses&quot;: LICENSES, &quot;categories&quot;: CATEGORIES, &quot;images&quot;: [], &quot;annotations&quot;: []}coco_output_test = { &quot;info&quot;: INFO, &quot;licenses&quot;: LICENSES, &quot;categories&quot;: CATEGORIES, &quot;images&quot;: [], &quot;annotations&quot;: []}annotation_root_path = '/root'annotation_name = os.path.join( annotation_root_path, &quot;via_export_coco_300_refine.json&quot;)# dataset = json.load(open(annotation_name, 'r'))#for ann in dataset['annotations']:# if not 'category_id' in ann.keys():# print(ann['id']) # 改标签的时候总有遗漏，导致后面步骤出问题，这里check一下，如果没有输出数字说明没有遗漏coco = COCO(annotation_name)catogry_info = coco.loadCats(coco.getCatIds( catNms=[&quot;truck&quot;, &quot;excavator&quot;, &quot;crane&quot;,&quot;other_machine&quot;,&quot;precast_concrete&quot;,&quot;steel&quot;,&quot;aggregates&quot;,&quot;timber&quot;,&quot;other_materials&quot;,&quot;personnel&quot;]))coco_output_train['categories'] = catogry_infococo_output_val['categories'] = catogry_infococo_output_test['categories'] = catogry_infoimage_ids = coco.getImgIds()[0:300]random.shuffle(image_ids) #随机取样，最后再用for image_id in image_ids[:200]: image_info = coco.loadImgs(image_id)[0] coco_output_train[&quot;images&quot;].append(image_info) # annotation_ids = coco.getAnnIds(imgIds=image_id) 这句调用的函数里面有个迭代器有问题，不用这个，自己写一个 annotation_ids = [] for anno in coco.imgToAnns[str(image_id)]: annotation_ids.append(anno['id']) for annotation_id in annotation_ids: annotation_info = coco.loadAnns(annotation_id)[0] # 防止接下来的步骤再出错，输出的文件中image_id一律不再是字符串 annotation_info['image_id'] = int(annotation_info['image_id']) coco_output_train[&quot;annotations&quot;].append(annotation_info)for image_id in image_ids[200:250]: image_info = coco.loadImgs(image_id)[0] coco_output_val[&quot;images&quot;].append(image_info) # annotation_ids = coco.getAnnIds(imgIds=image_id) 这句调用的函数里面有个迭代器有问题，不用这个，自己写一个 annotation_ids = [] for anno in coco.imgToAnns[str(image_id)]: annotation_ids.append(anno['id']) for annotation_id in annotation_ids: annotation_info = coco.loadAnns(annotation_id)[0] # 防止接下来的步骤再出错，输出的文件中image_id一律不再是字符串 annotation_info['image_id'] = int(annotation_info['image_id']) coco_output_val[&quot;annotations&quot;].append(annotation_info)for image_id in image_ids[250:]: image_info = coco.loadImgs(image_id)[0] coco_output_test[&quot;images&quot;].append(image_info) # annotation_ids = coco.getAnnIds(imgIds=image_id) 这句调用的函数里面有个迭代器有问题，不用这个，自己写一个 annotation_ids = [] for anno in coco.imgToAnns[str(image_id)]: annotation_ids.append(anno['id']) for annotation_id in annotation_ids: annotation_info = coco.loadAnns(annotation_id)[0] # 防止接下来的步骤再出错，输出的文件中image_id一律不再是字符串 annotation_info['image_id'] = int(annotation_info['image_id']) coco_output_test[&quot;annotations&quot;].append(annotation_info)with open('{}/anno_train_refine.json'.format(annotation_root_path), 'w') as output_json_file: json.dump(coco_output_train, output_json_file)with open('{}/anno_val_refine.json'.format(annotation_root_path), 'w') as output_json_file: json.dump(coco_output_val, output_json_file)with open('{}/anno_test_refine.json'.format(annotation_root_path), 'w') as output_json_file: json.dump(coco_output_test, output_json_file)","link":"/coco-dataset-split/"},{"title":"Apple Developer Program 注册中的天坑","text":"以中国大陆身份进行Apple Developer Program注册时需要验证身份。在这里Apple指出 “身份只能被验证一次” 。这里并不是开玩笑，而是验证流程 只能进行一次。如果因为某些原因没有走完注册流程，而是进行了第二次验证，那么恭喜你，你的身份将永远不能再用于开发者计划的注册。经过和客服电话交流得知这是由系统自动给出的处置，并且是最终的。 真够坑的，搞不好这是天意劝退搞iOS开发啊……","link":"/Apple-Developer-Program-trap/"}],"tags":[{"name":"目标识别","slug":"目标识别","link":"/tags/%E7%9B%AE%E6%A0%87%E8%AF%86%E5%88%AB/"},{"name":"研究笔记","slug":"研究笔记","link":"/tags/%E7%A0%94%E7%A9%B6%E7%AC%94%E8%AE%B0/"},{"name":"文献管理","slug":"文献管理","link":"/tags/%E6%96%87%E7%8C%AE%E7%AE%A1%E7%90%86/"},{"name":"LaTeX","slug":"LaTeX","link":"/tags/LaTeX/"},{"name":"学习笔记","slug":"学习笔记","link":"/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"随手心得","slug":"随手心得","link":"/tags/%E9%9A%8F%E6%89%8B%E5%BF%83%E5%BE%97/"}],"categories":[],"pages":[]}